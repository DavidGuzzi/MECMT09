# Script para replicar Tablas 1, 2, 3 y Figura 1 del paper de Sadoon et al. (2019)

import numpy as np
import pandas as pd
from pydynpd import regression
import matplotlib.pyplot as plt
import contextlib
import os
import sys
from scipy import stats
from datetime import datetime

# ------------------- Silenciar prints -------------------
@contextlib.contextmanager
def suppress_output():
    with open(os.devnull, "w") as devnull:
        old_stdout = sys.stdout
        old_stderr = sys.stderr
        sys.stdout = devnull
        sys.stderr = devnull
        try:
            yield
        finally:
            sys.stdout = old_stdout
            sys.stderr = old_stderr

# ------------------- ConfiguraciÃ³n global -------------------
np.random.seed(3649)
T_total_default = 20 
T_drop = 13
rho_values = [0.25, 0.5, 0.75]
N_values = [500, 5000]
selection_models = ['A', 'B']
reps = 500

# ------------------- Generador de datos -------------------
def generate_panel_data(N, rho, selection_type, T_total=T_total_default,
                        selection_rate=0.85,
                        sigma_alpha_ratio=1,
                        correlation=0.447,
                        non_stationary=False,
                        experiment_label=''):
    
    # ParÃ¡metros base (como en el paper)
    sigma_eta = 1
    sigma_u = 1
    sigma_alpha0 = sigma_alpha_ratio
    sigma_epsilon0 = 1

    # Generar componentes base independientes
    eta_i = np.random.normal(0, sigma_eta, N)
    alpha0_i = np.random.normal(0, sigma_alpha0, N)
    
    # Variables exÃ³genas y errores base
    z = np.random.normal(0, 1, (N, T_total))
    u = np.random.normal(0, sigma_u, (N, T_total))
    epsilon0 = np.random.normal(0, sigma_epsilon0, (N, T_total))
    
    # Correlaciones
    if correlation > 0:
        # Î±i = Î±0i + Î¸0Î·i, Îµit = Îµ0it + Ï‘0uit con Î¸0 = Ï‘0 = 0.5 para corr = 0.447
        correlation_param = 0.5 if abs(correlation - 0.447) < 0.01 else 0.25  # 0.25 para corr â‰ˆ 0.242
        alpha_i = alpha0_i + correlation_param * eta_i
        epsilon = epsilon0 + correlation_param * u
    else:
        alpha_i = alpha0_i
        epsilon = epsilon0
    
    # No estacionario
    if non_stationary:
        scaling = np.random.binomial(1, 0.5, size=(N, T_total)) + 1  # 1 o 2
        epsilon *= scaling
        u *= scaling

    # Generar y*it
    y = np.zeros((N, T_total))
    # CondiciÃ³n inicial (t=1): y*i1 = (2 + Î±i + Îµi1)/(1 - Ï)
    y[:, 0] = (2 + alpha_i + epsilon[:, 0]) / (1 - rho)
    # Proceso AR(1): y*it = 2 + Ïy*it-1 + Î±i + Îµit
    for t in range(1, T_total):
        y[:, t] = 2 + rho * y[:, t - 1] + alpha_i + epsilon[:, t]

    # Calibrar constante 'a' para lograr la tasa de selecciÃ³n deseada
    a = stats.norm.ppf(selection_rate)  # P(d*it > 0) = selection_rate
    
    # Proceso de selecciÃ³n
    d = np.zeros((N, T_total))
    d_star = np.zeros((N, T_total))
    
    if selection_type == 'A':
        # Modelo estÃ¡tico: d*it = a - zit - Î·i - uit (ecuaciÃ³n 40)
        d_star = a - z - eta_i[:, None] - u
        d = (d_star > 0).astype(int)
        
    elif selection_type == 'B':
        # Modelo dinÃ¡mico: d*it = a - 0.5dit-1 + zit - Î·i - uit (ecuaciÃ³n 41)
        for t in range(T_total):
            if t == 0:
                # Primera observaciÃ³n sin rezago
                d_star[:, t] = a + z[:, t] - eta_i - u[:, t]
            else:
                # Con rezago dinÃ¡mico
                d_star[:, t] = a - 0.5 * d[:, t-1] + z[:, t] - eta_i - u[:, t]
            d[:, t] = (d_star[:, t] > 0).astype(int)
    else:
        raise ValueError("Tipo de selecciÃ³n debe ser 'A' o 'B'")

    # Descartar primeras T_drop observaciones
    y_final = y[:, T_drop:]
    d_final = d[:, T_drop:]
    T_effective = T_total - T_drop

    # Ajustar requisitos segÃºn el experimento
    if experiment_label == 'short_T':
        start_t = 1  # Empezar desde t=1 en lugar de t=2
    else:
        start_t = 2  # Empezar desde t=2 (normal)
    
    # Crear panel balanceado
    panel = []
    for i in range(N):
        for t in range(start_t, T_effective):
            if experiment_label == 'short_T':
                # Para T corto: solo verificar 2 perÃ­odos consecutivos
                if t >= 1 and d_final[i, t] == d_final[i, t-1] == 1:
                    panel.append({
                        'id': i + 1,
                        'year': t + 1,
                        'n': y_final[i, t],
                        'L1.n': y_final[i, t-1],
                        'L2.n': y_final[i, t-2] if t >= 2 else y_final[i, t-1],  # Duplicar si no hay L2
                    })
            else:
                # Para experimentos normales: verificar 3 perÃ­odos consecutivos
                if d_final[i, t] == d_final[i, t-1] == d_final[i, t-2] == 1:
                    panel.append({
                        'id': i + 1,
                        'year': t + 1,
                        'n': y_final[i, t],
                        'L1.n': y_final[i, t-1],
                        'L2.n': y_final[i, t-2],
                    })
    
    return pd.DataFrame(panel)

# ------------------- Extraer coeficientes -------------------
def get_coefs(model, variable='L1.n'):
    """Extrae coeficiente y error estÃ¡ndar de la regresiÃ³n"""
    try:
        table = model.models[0].regression_table
        row = table[table['variable'] == variable]
        if not row.empty:
            coef = row['coefficient'].values[0]
            se = row['std_err'].values[0]
            return coef, se
        else:
            return np.nan, np.nan
    except Exception:
        return np.nan, np.nan
    

def get_timestamp():
    """Retorna timestamp formateado para logging"""
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

# ------------------- FunciÃ³n de simulaciÃ³n -------------------
def run_simulation(N, rho, sel_model, expt_label='',
                   T_total=T_total_default,
                   selection_rate=0.85,
                   sigma_alpha_ratio=1,
                   correlation=0.447,
                   non_stationary=False,
                   n_reps=None):  # Nuevo parÃ¡metro

    # Usar n_reps si se proporciona, sino usar global reps
    num_reps = n_reps if n_reps is not None else reps
    
    biases_ab, biases_sys = [], []
    ses_ab, ses_sys = [], []
    
    # Solo mostrar detalles para experimentos principales
    verbose = expt_label != 'figure1'
    
    if verbose:
        print(f"  Simulando: {expt_label} N={N} Ï={rho} Modelo={sel_model} ({num_reps} reps) [{get_timestamp()}]")
    
    for rep in range(num_reps):
        if verbose and rep % 100 == 0 and rep > 0:
            print(f"    Progreso: {rep}/{num_reps}")
            
        # Generar datos
        df = generate_panel_data(N, rho, sel_model,
                                 T_total=T_total,
                                 selection_rate=selection_rate,
                                 sigma_alpha_ratio=sigma_alpha_ratio,
                                 correlation=correlation,
                                 non_stationary=non_stationary)
        
        # Ajustar umbral segÃºn el experimento
        min_obs = 10 if expt_label != 'short_T' else 5
        
        if len(df) < min_obs:  # Necesitamos datos suficientes
            continue
            
        try:
            with suppress_output():
                # Arellano-Bond: AR(1) puro en primeras diferencias
                model_ab = regression.abond('n L1.n | gmm(n, 2:6) | nolevel', 
                                          df, ['id', 'year'])
                
                # System GMM: AR(1) con ecuaciones en niveles y diferencias
                model_sys = regression.abond('n L1.n | gmm(n, 2:6)', 
                                           df, ['id', 'year'])
            
            # Extraer resultados
            ab_coef, ab_se = get_coefs(model_ab, 'L1.n')
            sys_coef, sys_se = get_coefs(model_sys, 'L1.n')
            
            # Guardar si son vÃ¡lidos
            if not np.isnan(ab_coef):
                biases_ab.append(ab_coef - rho)
                ses_ab.append(ab_se)
            if not np.isnan(sys_coef):
                biases_sys.append(sys_coef - rho)
                ses_sys.append(sys_se)
                
        except Exception as e:
            continue

    # Calcular estadÃ­sticas finales
    result = {
        'N': N,
        'rho': rho,
        'selection': sel_model,
        'expt': expt_label,
        'AB_bias': np.mean(biases_ab) if biases_ab else np.nan,
        'AB_se': np.mean(ses_ab) if ses_ab else np.nan,
        'SYS_bias': np.mean(biases_sys) if biases_sys else np.nan,
        'SYS_se': np.mean(ses_sys) if ses_sys else np.nan,
        'AB_reps': len(biases_ab),
        'SYS_reps': len(biases_sys),
        'total_reps': num_reps
    }
    
    if verbose:
        print(f"    âœ“ AB: {result['AB_bias']:.4f} ({result['AB_reps']}/{num_reps} vÃ¡lidas)")
        print(f"    âœ“ SYS: {result['SYS_bias']:.4f} ({result['SYS_reps']}/{num_reps} vÃ¡lidas)")
    
    return result

# ------------------- ConfiguraciÃ³n de experimentos -------------------
experiments = [
    # TABLA 1 - Parte 1: Sin selecciÃ³n endÃ³gena
    {
        'label': 'no_endogenous', 
        'T_total': 20,
        'selection_rate': 0.85, 
        'sigma_alpha_ratio': 1, 
        'correlation': 0.0,  # SIN correlaciÃ³n
        'non_stationary': False
    },
    # TABLA 1 - Parte 2: Con selecciÃ³n endÃ³gena (baseline)
    {
        'label': 'baseline', 
        'T_total': 20,
        'selection_rate': 0.85, 
        'sigma_alpha_ratio': 1, 
        'correlation': 0.447,  # CON correlaciÃ³n
        'non_stationary': False
    },
    # TABLAS 2-3: Experimentos de sensibilidad
    {
        'label': 'short_T', 
        'T_total': 19,  # (Experimento I)
        'selection_rate': 0.85,  
        'sigma_alpha_ratio': 1, 
        'correlation': 0.447, 
        'non_stationary': False
    },
    {
        'label': 'more_selection', 
        'T_total': 20, 
        'selection_rate': 0.75,  # 25% selecciÃ³n (Experimento II)
        'sigma_alpha_ratio': 1, 
        'correlation': 0.447, 
        'non_stationary': False
    },
    {
        'label': 'high_alpha_ratio', 
        'T_total': 20, 
        'selection_rate': 0.85, 
        'sigma_alpha_ratio': 2,  # ÏƒÎ·/ÏƒÎµ = 2 (Experimento III)
        'correlation': 0.447, 
        'non_stationary': False
    },
    {
        'label': 'low_corr', 
        'T_total': 20, 
        'selection_rate': 0.85, 
        'sigma_alpha_ratio': 1, 
        'correlation': 0.242,  # Ï = 0.25 (Experimento IV)
        'non_stationary': False
    },
    {
        'label': 'nonstationary', 
        'T_total': 20, 
        'selection_rate': 0.85, 
        'sigma_alpha_ratio': 1, 
        'correlation': 0.447, 
        'non_stationary': True  # Experimento V
    },
]

# ------------------- Experimento especial para Figura 1 -------------------
def run_figure1_simulation():
    """SimulaciÃ³n especial para Figura 1 con muchos varios tamaÃ±os de muestra."""
    
    # TamaÃ±os de muestra para la figura
    N_figure = [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2200, 2400, 2600, 2800, 3000, 3200, 3400, 3600, 3800, 4000, 4200, 4400, 4600, 4800, 5000]
    rho_figure = [0.25, 0.5, 0.75]
    reps_figure = 500 
    
    figure_results = []
    total_sims = len(N_figure) * len(rho_figure) * 2  # 2 modelos de selecciÃ³n
    current_sim = 0
    
    print(f"Simulando {total_sims} configuraciones...")
    print(f"Usando {reps_figure} replicaciones por configuraciÃ³n")
    
    for N in N_figure:
        for rho in rho_figure:
            for sel_model in ['A', 'B']:
                current_sim += 1
                
                # Mostrar progreso cada 10 simulaciones
                if current_sim % 10 == 0 or current_sim == 1:
                    print(f"  [{current_sim}/{total_sims}] N={N}, Ï={rho}, Modelo={sel_model} [{get_timestamp()}]")

                res = run_simulation(N, rho, sel_model, 
                                   expt_label='figure1',
                                   T_total=20,
                                   selection_rate=0.85,
                                   sigma_alpha_ratio=1,
                                   correlation=0.447,
                                   non_stationary=False,
                                   n_reps=reps_figure) 
                
                # Cambiar label para identificar
                res['expt'] = 'figure1'
                figure_results.append(res)
    
    print(f"Figura 1 completada con {reps_figure} reps cada una [{get_timestamp()}]")
    return figure_results

# ------------------- Ejecutar simulaciones -------------------
print("="*80)
print(f"REPLICACIÃ“N SADOON ET AL. (2019) - INICIO: {get_timestamp()}")
print(f"Semilla: {3649} | Replicaciones por experimento: {reps}")
print("="*80)

all_results = []

# 1. EXPERIMENTOS PRINCIPALES (Tablas 1-3) con N = [500, 5000]
total_experiments = len(experiments) * len(N_values) * len(rho_values) * len(selection_models)
current_exp = 0

for expt in experiments:
    print(f"\n--- EXPERIMENTO: {expt['label'].upper()} --- [{get_timestamp()}]")
    for N in N_values:
        for rho in rho_values:
            for sel_model in selection_models:
                current_exp += 1
                print(f"[{current_exp}/{total_experiments}]", end=" ")
                
                res = run_simulation(N, rho, sel_model, 
                                   expt_label=expt['label'],
                                   T_total=expt['T_total'],
                                   selection_rate=expt['selection_rate'],
                                   sigma_alpha_ratio=expt['sigma_alpha_ratio'],
                                   correlation=expt['correlation'],
                                   non_stationary=expt['non_stationary'])
                all_results.append(res)

# 2. SIMULACIÃ“N ESPECIAL PARA FIGURA 1
print(f"\n{'='*80}")
print(f"EJECUTANDO SIMULACIÃ“N ESPECIAL PARA FIGURA 1 - INICIO: {get_timestamp()}")
print("(Varios tamaÃ±os de muestra para obtener lÃ­neas suaves)")
print(f"{'='*80}")

figure_results = run_figure1_simulation()
all_results.extend(figure_results)

# ------------------- Guardar resultados -------------------
df_all = pd.DataFrame(all_results)
df_all = df_all.round(5)  # Redondear para prolijidad
df_all.to_csv('resultados_simulaciÃ³n.csv', index=False)

print("\n" + "="*80)
print(f"SIMULACIONES COMPLETADAS - FIN: {get_timestamp()}")
print(f"Resultados guardados en 'resultados_simulaciÃ³n.csv'")
print(f"Total de experimentos: {len(df_all)}")
print("Experimentos incluidos:")
for exp_name in df_all['expt'].unique():
    count = len(df_all[df_all['expt'] == exp_name])
    print(f"   - {exp_name}: {count} configuraciones")
print("="*80)

import subprocess

# ------------------- Subida automÃ¡tica a Cloud Storage -------------------
try:
    bucket_name = "mecmt09-bucket"
    output_file = "resultados_simulaciÃ³n.csv"
    destino = f"gs://{bucket_name}/{output_file}"
    
    print(f"\nðŸš€ Subiendo {output_file} a {destino}...")
    subprocess.run(["gsutil", "cp", output_file, destino], check=True)
    print("âœ… Archivo subido exitosamente a Cloud Storage.")
except Exception as e:
    print("âš  Error al subir el archivo al bucket:", e)

# ------------------- Apagado automÃ¡tico de la VM -------------------
try:
    print("â» Apagando la instancia de Compute Engine...")
    subprocess.run([
        "gcloud", "compute", "instances", "stop", 
        "mecmt09-fast-vm", "--zone", "us-central1-c"
    ], check=True)
except Exception as e:
    print("âš  Error al intentar apagar la VM:", e)